TODO
	?remove feats est_feats from traversal methods structure? can be passed with ucand
	test with double hole (propagate from head) fixing scores
TODO speed up
	sparse vector should not store 0s
	boundry_ implement with hash table, use boost:hash (pointers)
	smeta and models make static fields in 
TODO code style
	?better structure for context links and link states?
	avoid passing spos down

111028
measures for paper (desk):
---------
BD b=30
-> dec test
Fri Oct 28 17:37:27 CEST 2011
Fri Oct 28 17:45:58 CEST 2011
=511s
-> dec test / sents (1994)
=0.26s /sent
-> resc
Time required for Cube Pruning execution: 305.02 seconds.
-> bleu (lap)
29.89 
---------
BD b=1
-> dec test
Fri Oct 28 18:03:12 CEST 2011
Fri Oct 28 18:09:31 CEST 2011
=379s
-> dec test / sents (1994)
=0.19 s /sent
-> resc
Time required for Cube Pruning execution: 198.42 seconds
-> bleu (lap)
29.07
---------
BD b=30
-> dec test
Fri Oct 28 18:40:29 CEST 2011
Fri Oct 28 18:44:00 CEST 2011
=221s
-> dec test / sents (1994)
=0.11s /sent
-> resc
Time required for Cube Pruning execution: 43.45 seconds.
-> bleu (lap)
25.61


111019-21
Aggressive update not good!
less features, no need to force update on rarel triggered feats since there are no rarely triggered feats.
-
feats : avg-cnt-lnkBin-cln binWordPenalty (split 1 ... 6lin) (lap) 
s1: 0.207607 0.253908 \ 0.210468 0.25487
//NB init feats to WordPenalty
-
feats : avg-cnt-lnkBin-cln binWordPenalty (split 1 2lin) (lap) 
s1:20.33 25.18 \ 20.58 25.18
//NB init feats to WordPenalty
-
feats : avg-cnt-lnkBin-cln  (lap)
s2:21.34 24.73 \ 21.99 24.95
//aggressive update still fail
-
feats : avg-cnt-lnkBin-clnBin-cln (lap)
s1: 20.53 25.36 \ 20.32 25.20
//combination of bin-lin fail
-
feats : avg-cnt-lnkBin-clnBin  (lap)
s1: 20.42 25.36 \ 20.63 25.43
//bin version fail~=, only 2 values are effectively used 1 and 2
//3 links only update previously selected
//0 links first loop, every time a wrong leaf if choosen the correction is still a leaf so diff vector has clkBin_0 feat to 1-1=zero 
-
feats : avg-cnt-lnkBin-cln  (lap) * (cln=count established links)
s1: 20.59 25.43 \ 20.56 25.60
-
feats : avg-cnt-lnkBin-lnk  (lap)
s1: 20.40 25.11
//combination of bin-lin fail
-
feats : avg-cnt-lnkBin  (lap) *
s1: 20.74 25.31
//bin feats win, only 3 values but not linear:
//LanguageModel_LNK-BIN_1 37.889952667814114
//LanguageModel_LNK-BIN_2 -10.641028399311532
//LanguageModel_LNK-BIN_3 -27.248924268502581
-
feats : avg-cnt-lnk					
(lap)
soglia	1	2	4	8	50
train	20.0393	20.999	22.7089	23.7641	26.23
test	24.8937	24.6546	24.3191	23.6216	22.87
-
feats : avg-cnt-lnk -BASE (lap)
s1: 19.67 24.57
-
feats : sum-cnt-lnk (lap)
s1: 19.27 24.80
-
feats : avg-cnt
(lap)
soglia	1	50
train   18.67	25.99
test	22.77	20.90
-
feats : sum-cnt (lap)
s1: 17.90 21.95
-
feats : lnk (lap)
s1: 18.91 24.24 
-
feats : cnt (lap)
s1: 18.35 21.25
-
feats : avg
(lap)
soglia	1	50
train   17.80	25.90
test	21.99	21.14
-
feats : Base
(lap)
soglia	1	50
train   17.51	24.47
test	23.30	23.29
-
why is tst > train? the test contains diff type of sents? (shorter, easier..)


111007
APA:
(desk)
0.236052 0.0931652
0.237324 0.218246
0.237111 0.0931247
0.233586 0.139822

AP:(time half comp to B1 on first tst sentence 0.08/0.16(B1)/0.25(B30))
(desk)
0.241862 0.232468
0.242376 0.23122
0.244555 0.23161
0.243041 0.232562
-
P: distinguishing LM_EST feat
(desk)
0.167042
0.0285186
0.166069
0.0184826
0.163937
0.126759
0.16779
0.127539
-
P:(iteration\ dev | tst = BLEU/10)
(desk)
0.167042 0.0285186
0.166069 0.0184826
0.163937 0.126759
0.16779 0.127539
-
PA: (iteration\ dev | tst = BLEU)
(desk)
23.61 14.68
23.24 11.47

111005
experiments on fr-it europarl
cdec mert B30 29.8999
cdec mert B1  29.575

110909
OK!	propagation (see 110909log)

110825
OK!	smarter queue update (avoid full deletion)
OK!	mem leaks (valgrind) on quick & lat
	-test if faster on whole corpus:	
	time,	score
GU++    66s  	12.37 //110907 Propagation full
GU+	65s	13.44 //110905 LM all out states
GU	63s	13.44
CP	159s	32.14
	to compare with brute try with no LM 
	ON LAPTOP (compare with 110713)
NEW PROPAG. GU	37s 	12.78
CP		66s	10.25 (match 110713)
	ON DESKTOP
NEW PROPAG. GU	54s	12.01
BRUTE PROP. GU	67s	12.01
CP		87s	6.23
FULL		102s	6.22
	-comments:
	GU is always faster (60% in last with LM, new propagation is faster)
	scores are meaningless

110713 
OK!	adapt language model

110713
OK!	mem leaks (valgrind)
	-test on whole corpus:
	time, score (no LM no extra training)
GU	37s , 12.44
CP	62s , 10.25
	
110711 
OK!	convert ucands structure in out_hg
OK!	free memory (test with val girnd)

110707 IMPLEMENT DECODING/TRAINING LOOP (only local feats)
then execute exp and record new lower-boundary BLEU
OK!	method to Pop heap
OK! 	free memory policy
OK!	pop best
OK!	correct weight if wrong
OK!	update queue if wrong
OK!	structure for borders
OK!	update queue if correct
MAIN LOOP DONE

110705 MODIFY UCAND AND SCORING
OK! 	use models.AddFeaturesToUCand() to score
OK!	do not pass out_hg in AddFeaturesToUCand()
OK!	pass UCand in AddFeaturesToUCand()
OK!	move feature vectors from HG::Edge to UC
OK!	remove added field from HG::Edge forest feat vector
OK!	replace bottom up data structs for states j_ D with undir
OK!	do not use UCandidate.out_edge_ 
OK!  	remove UCand.j_ and D add pointer structure

1110702 BOUNDARIES EXPS
(exec time is 2min on laptop 3+min on desk)
BLEU 
0.322487 (normal, beam 30)
0.31336  (normal, beam 1)
0.257092 (with rude action score[remove *p from viterbi score], beam 30)
0.239234 (with rude action score[remove *p from viterbi score], beam 1)

10603 TEST LEARNING
GL S1)	
	unique list of [^U]Candidates OK!
	init with leafs OK!
	use same bottom-up features OK!
	pass hg edges mask OK!
	pop best scoring leaf OK!
	check if leaf is has correct edge OK!
	update weigths with PA OK!
	rescore queue OK!


